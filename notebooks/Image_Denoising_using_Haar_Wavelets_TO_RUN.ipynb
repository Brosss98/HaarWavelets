{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEfDhLrvu3rj"
      },
      "source": [
        "# Project: **Image Denoising using Haar Wavelets**\n",
        "\n",
        "### Author: *Mario Medone*\n",
        "\n",
        "##### Course: *Digital Signal & Image Processing*\n",
        "\n",
        "<br>\n",
        "\n",
        "In this notebook, we will speak about **image denoising**, in particular about how the wavelet transform can be useful to enhance the quality of an image affected by noise.\n",
        "\n",
        "After a brief introduction on the 2D Haar wavelet transform, we will speak about a method to denoise images through multiple levels wavelet decomposition which is based on a thresholding function: we will present different types of it, such as **hard thresholding** and **soft thresholding**. We will also speak about the best possible choice of the threshold parameter required by the thresholding function: firstly, we will introduce the empirical method to choose the best value for the parameter, then we will provide some methods to compute it, such as the **VisuShrink**, **BayesShrink** and a modified version of the first one, which we called **VisuShrinkMod**.\n",
        "\n",
        "To do this, we will see some experiments using the *Lena* image and we will comment the results.\n",
        "<br><br>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jI_9hr8x8uL"
      },
      "source": [
        "## 1. Introduction\n",
        "\n",
        "Nowadays, cameras and images have become common parts of our life. Anyone with a device equipped with a camera can take a photograph or video, then edit, save and share it. Not only this. Cameras can be useful for various activities: for example, intelligent traffic system, bio-medical imaging, image processing for medical diagnostic, multimedia application, object tracking, and many more.\n",
        "\n",
        "So, there is a great interest in this technological field, and there are many many studies that deepen every facet.\n",
        "\n",
        "<br>\n",
        "\n",
        "The one we want to focus on is that the images are most often damaged by noise. Noise can be defined as any unwanted interference in image data and, typically, it corresponds to higher frequencies. Noise can appear in images from multiple sources, for example during the acquisition step or the transmission process.\n",
        "\n",
        "As a result, denoising is one of the major challenges in the field of image processing to improve image quality: this is the process that permits to estimate the original image by suppressing the noise in a noisy image.\n",
        "\n",
        "In mathematical notation, a noisy image can be described as in the equation below\n",
        "\n",
        "$$ Img_N(x,y) = Img(x,y) + N(x,y) $$\n",
        "\n",
        "where $ Img(x,y) $ is the original image, $ N(x,y) $ is the noise, and $ Img_N(x,y) $ is the resulting noisy image.\n",
        "\n",
        "<br>Noises usually present in an image are uniform noise, noise impulse, salt & pepper, Gaussian noise, or others. In this work, we focus on Gaussian noise: this type of noise can include other types of noise implicitly and it is the most frequent noise that appears in the images. We assume that it has a probability density function equal to the one of the normal distribution, also called Gaussian distribution. The probability density function $ p $ of a Gaussian random variable $ z $ is given by\n",
        "\n",
        "$$ p(z) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\cdot e^{-\\frac{(z-\\mu)^2}{2\\sigma^2}} $$\n",
        "\n",
        "where $ \\mu $ is the mean value and $ \\sigma $ is the standard deviation.\n",
        "\n",
        "<br>Furthermore, the Gaussian noise has the property that, after a 2D wavelet transform, it remains independent from each other at different frequency bands. If we increase the level decomposition of the wavelet transform, the noise energy reduces rapidly, instead the original image signal keeps its local maxima in the same location and its energy will not reduce rapidly as the noise one. So, this is a very important feature that can permit to obtain good image denoising results, by thresholding the wavelet coefficients in the right way.\n",
        "\n",
        "<br>This notebook is organized as follows:\n",
        "\n",
        "- section 2 is devoted for literature review which includes a brief introduction to 2D Haar wavelet transform, the denoising procedure and the wavelet thresholding methods; there is also a long discussion on how to choose the optimal value for the threshold parameter;\n",
        "\n",
        "- in section 3, we implement the introduced thresholding methods and the denoising procedure;\n",
        "\n",
        "- In section 4, we test what we have implemented to make some conclusion about which thresholding method (and parameter) can be the optimal one;\n",
        "\n",
        "- finally, in section 5, we write our conclusions and considerations about all the work.\n",
        "<br><br>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQpBbM1bz1SK"
      },
      "outputs": [],
      "source": [
        "# Import required modules\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pywt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqhhO7-tyDn6"
      },
      "source": [
        "## 2. Literature review\n",
        "\n",
        "We give a brief introduction about what is the 2D Haar wavelet transform and how it works. Furthermore, we speak a little about the denoising method we will implement, the thresholding methods and about how we can choose the best value for the threshold parameter."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBtKu2cIyAIk"
      },
      "source": [
        "### 2.1. 2D Haar wavelet transform\n",
        "\n",
        "Starting from what we have learned in class about the 1D Haar wavelets, we know that a one dimensional image can be treated as sequences of coefficients, approximation and detail ones.\n",
        "<br>We also introduced the *scaling function* $ \\phi $ and the *wavelet function* $ \\psi $ that are useful in the wavelet decomposition process.\n",
        "\n",
        "<br>Thus, the wavelet transform for an image, as a 2D signal, will be obtained from 1D wavelet tranform. We can get the scaling function and wavelet function for 2D by multiplying two 1D functions. The scaling function is obtained by multipling two 1D scaling ones: $ \\phi(x,y) = \\phi(x)\\phi(y) $. The wavelet functions are obtained by multiplying two wavelet functions or one wavelet and one scaling function for 1D case. In the 2D case, there exist three wavelet functions that scan details in:\n",
        "- horizontal, $ \\psi^{(1)}(x,y) = \\phi(x)\\cdot\\psi(y) $;\n",
        "- vertical, $ \\psi^{(2)}(x,y) = \\psi(x)\\cdot\\phi(y) $;\n",
        "- diagonal, $ \\psi^{(3)}(x,y) = \\psi(x)\\cdot\\psi(y) $.\n",
        "\n",
        "This may be represented as a four channels perfect decomposition filter bank as shown below.\n",
        "<br><br>\n",
        "<center width=\"100%\" style=\"padding:10px\"><img src=\"../docs/images/image1.png\" width=\"650px\"></center>\n",
        "\n",
        "<br>In particular for a 2D Haar wavelet transform of an image, $ a_L $ represents a low pass filter and $ a_H $ represents a high pass filter. First, each row of the image is filtered by $ a_L $ and $ a_H $, and then the filtered results are down-sampled by 2. After that, each of the resulting columns is further low pass and high pass filtered using $ a_L $ and $ a_H $. Again we down-sampling by 2, and we finally obtain the images decomposed into four different sub-bands. There exist three types of detail coefficients for each resolution: horizontal detail ($ HL $), vertical detail ($ LH $) and diagonal one ($ HH $). $ LL $ corresponds to the approximation of the image, on which we can repeat the operations using the second stage of identical filter bank (like before). Thus, a typical 2D wavelet transform can generate hierarchical structure as the one shown below.\n",
        "<br><br>\n",
        "<center width=\"100%\" style=\"padding:10px\"><img src=\"../docs/images/image2.png\" width=\"650px\"></center>\n",
        "\n",
        "<br>Starting from a 2D Haar wavelets structure, we can reconstruct the original image, processing it through the *2D inverse Haar wavelet transform*.\n",
        "\n",
        "<br>For our purpose, we will use an already implemented version of the 2D Haar wavelet transform, focusing more our attention on the image denoising part.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxdP5iJDyG3x"
      },
      "source": [
        "### 2.2. Denoising procedure\n",
        "\n",
        "Up to this point, we have understood why wavelet transform is a good utility to clean images from noise and how wavelets work.\n",
        "\n",
        "Now, we want to unerdstand the approach to do image denoising using wavelet transform. The work we have to do can be summarized in the following simple steps:\n",
        "\n",
        "1. Apply multiple levels 2D Haar wavelet transform on a noisy image; the image will be divided into four sub-bands: the low-low ($ LL_k $) that will contain the approximation coefficients and the other three high-frequency sub-bands ($ HL_k $, $ LH_k $ and $ HH_k $) that will contain the different detail coefficients (horizontal, vertical and diagonal), with $k$ the level of decomposition.\n",
        "\n",
        " After the first level, the $ k $ level 2D Haar wavelet transform will be applied only to the $ LL_{k-1} $ to obtain the subsequent decomposition in $ LL_k $, $ HL_k $, $ LH_k $ and $ HH_k $ sub-bands;\n",
        "\n",
        "2. Apply a thresholding method on the three high-frequency sub-bands; we have to define a threshold value and pass it, together with each sub-band, to the thresholding method which operates over each pixel of the sub-band as follows:\n",
        " - if the pixel value is less than the threshold value, it sets the pixel value to zero;\n",
        " - otherwise, leave it, or modify it (a little), and skip to the next pixel;\n",
        " \n",
        " This step is repeated until all the pixels have been visited;\n",
        "\n",
        "3. Apply one level 2D inverse Haar wavelet transform on the latest four sub-bands ($ LL_k $, $ HL_k $, $ LH_k $ and $ HH_k $) to obtain a denoised $ LL_{k-1} $ sub-band, possibly without noise;\n",
        "\n",
        "4. Step 2 and 3 are repeated at each level of decomposition, until we rebuild the (possibly) denoised image with the latest inverse wavelet transform (using $ LL_1 $, $ HL_1 $, $ LH_1 $ and $ HH_1 $ sub-bands to obtain the final image).\n",
        "\n",
        "4. Finally, we can use different types of metrics (such as *MSE* or *PSNR*) to compare the new image and the original one and, so, to evalute the denoising method.\n",
        "\n",
        "<br>As we have said before, noise mainly dominates the detail coefficients in the wavelet transform; if we can set a reasonable threshold, we can drop all the noise contaminated detail coefficients to zero to remove noise from our images. The following question is how we use the threshold to reduce\n",
        "noise in an image and the crucial ingredient in this procedure is: how to decide the value of the threshold and the thresholding function? There are many possible solutions, we will explain and compare some methods in detail.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9KH4Pw3yLK2"
      },
      "source": [
        "### 2.3. How do we do thresholding?\n",
        "\n",
        "The key problem to the image denoising of wavelet is how to carry on correction to the coefficients of transformation.\n",
        "\n",
        "Let $ W $ be a wavelet decomposition detail sub-band (horizontal, vertical or diagonal). Let us apply threshold zeroing with a fixed threshold value $ T $ for $ W $. Let us denote the thresholded sub-band as $ W' $.\n",
        "<br>Having said that, we can introduce two ways to perform thresholding: **hard thresholding** and **soft thresholding**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rO3mZRYMype-"
      },
      "source": [
        "#### 2.3.1. Hard Thresholding\n",
        "\n",
        "The hard thresholding strategy compares the absolute value of the wavelet coefficients with a threshold value of $ T $. It preserves the wavelet coefficients whose absolute values are greater than the threshold. If the wavelet coefficients are below the threshold, they are setted to zero.\n",
        "\n",
        "It can be described with the following equation:\n",
        "\n",
        "$$ W'(x,y) = \\begin{cases} W(x,y), & |W(x,y)| \\ge T \\\\ 0, & |W(x,y)| < T \\end{cases} $$\n",
        "\n",
        "<br>\n",
        "\n",
        "As shown in the representation below, the hard thresholding function is discontinuous. Although it has the advantage of retaining the image local features (such as edges), it may produce visual distortion in the reconstructed image.\n",
        "<br><br>\n",
        "<center width=\"100%\" style=\"padding:10px\"><img src=\"../docs/images/image3.png\" width=\"500px\"></center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bq6wvGOKywqJ"
      },
      "source": [
        "#### 2.3.2. Soft Thresholding\n",
        "\n",
        "The soft thresholding function is very similar to hard thresholding but it shifts wavelet coefficients towards zero. The wavelet coefficients whose absolute values are greater than $ T $ are subtracted by $ T $, and all of the other coefficients are set to zero. After soft thresholding, the wavelet coefficients are smoother in the wavelet domain and, also, the reconstructed image looks smoother than the one obtained with the hard thresholding strategy.\n",
        "\n",
        "It can be described with the following equation:\n",
        "\n",
        "$$ W'(x,y) = \\begin{cases} \\text{sign}(W(x,y)) \\cdot (|W(x,y)|-T), & |W(x,y)| \\ge T \\\\ 0, & |W(x,y)| < T \\end{cases} $$\n",
        "\n",
        "<br>\n",
        "\n",
        "We can see how the soft threshold works in the representation below.\n",
        "<br><br>\n",
        "<center width=\"100%\" style=\"padding:10px\"><img src=\"../docs/images/image4.png\" width=\"500px\"></center>\n",
        "\n",
        "<br>\n",
        "\n",
        "We can now implement these two thresholding methods in Python.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fTAsJK-By_ME"
      },
      "outputs": [],
      "source": [
        "# Function that applies the selected thresholding method to the sub-band S using threshold value T\n",
        "def thresholding(S, thresh_method, T):\n",
        "  \n",
        "  # Check the threshold value: if it does not respect the rule, raise an error\n",
        "  if T < 0:\n",
        "    raise ValueError(\"The threshold value T must be greater than zero!\")\n",
        "\n",
        "  # Hard thresholding\n",
        "  if thresh_method == \"hard\":\n",
        "    S[np.abs(S) < T] = 0\n",
        "    return S\n",
        "\n",
        "  # Soft thesholding\n",
        "  elif thresh_method == \"soft\":\n",
        "    S_new = np.sign(S) * (np.abs(S) - T)\n",
        "    S_new[np.abs(S) < T] = 0\n",
        "    return S_new\n",
        "\n",
        "  # If thresh_method is not equal to one of the before, it is incorrect: raise an error\n",
        "  else:\n",
        "    raise ValueError(\"The selected thresholding method does not exist!\")\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elMqd9ohynj1"
      },
      "source": [
        "#### 2.3.3. The threshold value\n",
        "\n",
        "As we have already said, the selection of the threshold is critical for the performance of denoising images using this method. If the value is bigger, it would also remove the useful part of the signal, such as important image features; instead, if the value is too small, it is possible that it cannot remove noise sufficiently or, at worst, it would not be able to clean the image from noise at all.\n",
        "\n",
        "For this work, we mainly focus on two of the most commonly used methods to define the threshold: *VisuShrink* and *BayesShrink*, introducing also a modified version of the first which we called *VisuShrinkMod*.\n",
        "\n",
        "But, before we have a look to their characteristics, we want to take a step back and observe how the results vary as the threshold value varies and, therefore, the impact it has on the denoising algorithm.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6DAG2HO36VY"
      },
      "source": [
        "Suppose we have done a one level 2D Haar wavelet decomposition: we have the approximation coefficients ($ LL $ sub-band) and the three detail coefficients ($ LH $, $ HL $, $ HH $ sub-bands). We want to apply one of the thresholding methods we introduce. So, we pick each of the high-frequency sub-bands and we apply the thresholding method. But we have to pass also a threshold value. How do we decide the value of the threshold?\n",
        "\n",
        "Helping us with a toy image, we will see through a one level wavelet decomposition how the threshold modifies the detail coefficients and, thus, the image itself.\n",
        "\n",
        "<br>\n",
        "\n",
        "At the beginning, we can load the image and test directly the thresholding methods on it, without add the noise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "6vegTPNV5LKV",
        "outputId": "df698be8-5563-426c-dbcd-828f0dd5daf9"
      },
      "outputs": [],
      "source": [
        "# Load toy image\n",
        "url = \"../data/images/toy1.png\"\n",
        "original = cv2.imread(url, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "# Show the image\n",
        "plt.figure(figsize=(7, 7))\n",
        "plt.imshow(original, cmap=plt.cm.gray)\n",
        "plt.title(\"Toy - Original image\", pad=10)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msiBAW0g5UUk"
      },
      "source": [
        "We also define a method which permits to plot the four sub-bands without having to rewrite all these lines of code every time.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cj6BFg2C5QsW"
      },
      "outputs": [],
      "source": [
        "# Function that permits to plot the four sub-bands of a wavelet decomposition\n",
        "def plotSubBands(LL, LH, HL, HH):\n",
        "  \n",
        "  plt.subplot(1, 4, 1)\n",
        "  plt.imshow(LL, cmap=plt.cm.gray)\n",
        "  plt.title(\"LL sub-band (approximation coefficients)\", pad=10)\n",
        "\n",
        "  plt.subplot(1, 4, 2)\n",
        "  plt.imshow(LH, cmap=plt.cm.gray)\n",
        "  plt.title(\"LH sub-band (horizontal detail coefficients)\", pad=10)\n",
        "\n",
        "  plt.subplot(1, 4, 3)\n",
        "  plt.imshow(HL, cmap=plt.cm.gray)\n",
        "  plt.title(\"HL sub-band (vertical detail coefficients)\", pad=10)\n",
        "\n",
        "  plt.subplot(1, 4, 4)\n",
        "  plt.imshow(HH, cmap=plt.cm.gray)\n",
        "  plt.title(\"HH sub-band (diagonal detail coefficients)\", pad=10)\n",
        "\n",
        "  plt.show()\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "z-W8DQNb5hCk",
        "outputId": "985f5ecf-40ad-4b89-c1cf-5a14e38abc41"
      },
      "outputs": [],
      "source": [
        "# Apply a one level 2D Haar wavelet decomposition to obtain the four sub-bands\n",
        "LL, (LH, HL, HH) = pywt.dwt2(original, \"haar\")\n",
        "\n",
        "# Show them\n",
        "plt.figure(figsize=(28, 7))\n",
        "plotSubBands(LL, LH, HL, HH)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_95yXvM5kZE"
      },
      "source": [
        "Now we apply the *hard thresholding* method using three different values for the threshold parameter. We will plot the sub-bands in each of the cases and we will comment the results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gCopXNH75qJr",
        "outputId": "2946f640-2e87-4f09-db31-46656e8bac73"
      },
      "outputs": [],
      "source": [
        "# Apply the hard thresholding with three values for the threshold parameter and see what happens\n",
        "threshold_values = [10, 50, 90]\n",
        "thresholded_images = []\n",
        "\n",
        "for threshold_value in threshold_values:\n",
        "\n",
        "  LH_new = thresholding(S=LH.copy(), thresh_method=\"hard\", T=threshold_value)\n",
        "  HL_new = thresholding(S=HL.copy(), thresh_method=\"hard\", T=threshold_value)\n",
        "  HH_new = thresholding(S=HH.copy(), thresh_method=\"hard\", T=threshold_value)\n",
        "\n",
        "  # Show the sub-bands\n",
        "  print(\"Threshold value: {}\\n\".format(threshold_value))\n",
        "  plt.figure(figsize=(28, 7))\n",
        "  plotSubBands(LL, LH_new, HL_new, HH_new)\n",
        "  plt.show()\n",
        "\n",
        "  # Rebuild the image using the thresholded detail sub-bands\n",
        "  thresholded_image = pywt.idwt2((LL, (LH_new, HL_new, HH_new)), \"haar\")\n",
        "  thresholded_image[thresholded_image < 0] = 0\n",
        "  thresholded_image[thresholded_image > 255] = 255\n",
        "  thresholded_images.append(np.round(thresholded_image))\n",
        "\n",
        "  print(\"\\n-------------------------------------------------------------------\\n\\n\")\n",
        "\n",
        "hard_representative = thresholded_images[1]\n",
        "\n",
        "# Show the images before and after hard thresholding\n",
        "plt.figure(figsize=(15, 15))\n",
        "\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.imshow(original, cmap=plt.cm.gray)\n",
        "plt.title(\"Original image\", pad=10)\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.imshow(thresholded_images[0], cmap=plt.cm.gray)\n",
        "plt.title(\"Thresholded image - threshold = {}\".format(threshold_values[0]), pad=10)\n",
        "\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.imshow(thresholded_images[1], cmap=plt.cm.gray)\n",
        "plt.title(\"Thresholded image - threshold = {}\".format(threshold_values[1]), pad=10)\n",
        "\n",
        "plt.subplot(2, 2, 4)\n",
        "plt.imshow(thresholded_images[2], cmap=plt.cm.gray)\n",
        "plt.title(\"Thresholded image - threshold = {}\".format(threshold_values[2]), pad=10)\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-7Nx3zY5vA0"
      },
      "source": [
        "What we can see through the plot of the detail coefficients is that with a higher value of the threshold parameter, more of the coefficients are set to zero, as we expected. \n",
        "\n",
        "So, what does it happen in the image? When we will apply the 2D Haar inverse transform with the thresholded detail coefficients, we will obtain an image that appears more granulated, particularly on the edges of the objects in it. This is because, for example, two nearby pixels that has a similar gray level will be represented by an approximation coefficient (the mean of the two) and a detail coefficient that will be very small because the two gray levels are very similar. So, if we apply the thresholding scheme, this detail will be set to zero and, when we rebuild the image, these two pixels will have the same value.\n",
        "\n",
        "With hard thresholding, if the detail value is greater than the threshold, nothing is done: this is why we obtain a more granulated result respect, for example, to soft thresholding.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3wiFmox5ywV"
      },
      "source": [
        "Now we apply the *soft thresholding* method using three different values for the threshold parameter. We will plot the sub-bands in each of the cases and we will comment the results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YXY35yZZ5s7E",
        "outputId": "a816d2fb-3e3b-4a82-e25c-c6a734c6f55a"
      },
      "outputs": [],
      "source": [
        "# Apply the soft thresholding with three values for the threshold parameter and see what happens\n",
        "threshold_values = [10, 50, 90]\n",
        "thresholded_images = []\n",
        "\n",
        "for threshold_value in threshold_values:\n",
        "  \n",
        "  LH_new = thresholding(S=LH.copy(), thresh_method=\"soft\", T=threshold_value)\n",
        "  HL_new = thresholding(S=HL.copy(), thresh_method=\"soft\", T=threshold_value)\n",
        "  HH_new = thresholding(S=HH.copy(), thresh_method=\"soft\", T=threshold_value)\n",
        "\n",
        "  # Show the sub-bands\n",
        "  print(\"Threshold value: {}\\n\".format(threshold_value))\n",
        "  plt.figure(figsize=(28, 7))\n",
        "  plotSubBands(LL, LH_new, HL_new, HH_new)\n",
        "  plt.show()\n",
        "\n",
        "  # Rebuild the image using the thresholded detail sub-bands\n",
        "  thresholded_image = pywt.idwt2((LL, (LH_new, HL_new, HH_new)), \"haar\")\n",
        "  thresholded_image[thresholded_image < 0] = 0\n",
        "  thresholded_image[thresholded_image > 255] = 255\n",
        "  thresholded_images.append(np.round(thresholded_image))\n",
        "\n",
        "  print(\"\\n-------------------------------------------------------------------\\n\\n\")\n",
        "\n",
        "soft_representative = thresholded_images[1]\n",
        "\n",
        "# Show the images before and after hard thresholding\n",
        "plt.figure(figsize=(15, 15))\n",
        "\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.imshow(original, cmap=plt.cm.gray)\n",
        "plt.title(\"Original image\", pad=10)\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.imshow(thresholded_images[0], cmap=plt.cm.gray)\n",
        "plt.title(\"Thresholded image - threshold = {}\".format(threshold_values[0]), pad=10)\n",
        "\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.imshow(thresholded_images[1], cmap=plt.cm.gray)\n",
        "plt.title(\"Thresholded image - threshold = {}\".format(threshold_values[1]), pad=10)\n",
        "\n",
        "plt.subplot(2, 2, 4)\n",
        "plt.imshow(thresholded_images[2], cmap=plt.cm.gray)\n",
        "plt.title(\"Thresholded image - threshold = {}\".format(threshold_values[2]), pad=10)\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4OM4KJK53CX"
      },
      "source": [
        "What we can see through the plot of the detail coefficients is that with a higher value of the threshold parameter, more of the coefficients are set to zero, as we expected, and the coefficient that are greater than the threhsold value are shifted by the threshold value itself, appearing more attenuated.\n",
        "\n",
        "So, what does it happen in the image? When we will apply the 2D Haar inverse transform with the thresholded detail coefficients, we will obtain an image that appears less granulated but more smoother and blurrier than the one obtained with the hard thresholding. This is because, for example, two nearby pixels that has not a similar gray level will be represented by an approximation coefficient (the mean of the two) and a detail coefficient that will be a number (for example 100). So, if we apply the thresholding scheme with a threshold value of 80, this detail will be reduced a lot (to 20) and, when we rebuild the image, these two pixels will be very similar in term of gray level and we will obtain a smoother and bluerrier image than before.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-47E5ssE56zE"
      },
      "source": [
        "So, now we can make a comparison between hard and soft thresholding, with a fixed threshold parameter.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 560
        },
        "id": "J4jl7wu26Lwo",
        "outputId": "2d5d57ba-3dcc-4460-855a-98b66d52b671"
      },
      "outputs": [],
      "source": [
        "# The fixed threshold parameter used to obtain hard_representative and soft_representative is 50\n",
        "plt.figure(figsize=(30, 10))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.imshow(hard_representative, cmap=plt.cm.gray)\n",
        "plt.title(\"Hard thresholding - threshold = 50\", pad=10)\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.imshow(soft_representative, cmap=plt.cm.gray)\n",
        "plt.title(\"Soft thresholding - threshold = 50\", pad=10)\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.imshow(np.abs(hard_representative-soft_representative), cmap=plt.cm.gray)\n",
        "plt.title(\"Absolute difference: Hard vs. Soft\", pad=10)\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTELoo9u6MIv"
      },
      "source": [
        "As we just said, with hard thresholding we obtain an image in which the edges of the objects are more granulated, instead, with the soft one, they are more blurried.\n",
        "\n",
        "We also plot the difference between the two methods to emphasize even more that the most difference is in how the two methods treat the edges in the image.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6gdlgc96Ur8"
      },
      "source": [
        "#### 2.3.3.1. How do we start to do denoising? \n",
        "#### *The choice of the optimal threshold value*\n",
        "\n",
        "We know how to deal with images through the 2D Haar wavelet transform and we also know the behavior of hard and soft thresholding. Now, the question is: how can we choose the best possible threshold value? Does it changes if we use multiple levels decomposition?\n",
        "\n",
        "So, we will see how we can manually tune the threshold parameter and the best choice for it.\n",
        "\n",
        "<br>\n",
        "\n",
        "Thus, we firstly have to define a method that permits to add Gaussian noise to an image: we define *addingNoise()* funciton to reach this scope.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "czfR1FB0AAg8"
      },
      "outputs": [],
      "source": [
        "# Function that add Gaussian noise to an image\n",
        "def addingNoise(original, mean, std):\n",
        "  \n",
        "  # Set a seed for reproducibility purpose\n",
        "  np.random.seed(0)\n",
        "  # Compute gaussian noise with mean and std passed to the function (mean is typically 0)\n",
        "  gaussian = np.random.normal(mean, std, original.shape)\n",
        "  # We add the noise to the original image and adapt the noisy image to the range 0-255\n",
        "  noisy = np.round(original + gaussian)\n",
        "  noisy[noisy > 255] = 255\n",
        "  noisy[noisy < 0] = 0\n",
        "\n",
        "  # Return the noisy image in uint8 values\n",
        "  return np.uint8(noisy)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4EvBVKA_617"
      },
      "source": [
        "Then, we import our test image (*Lena* image) and generate a noisy version of it, adding a Gaussian noise with standard deviation equals to 10."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "id": "D1Yis5F76oUk",
        "outputId": "c53cecd3-e776-4511-bf1d-ba84fa41fe0a"
      },
      "outputs": [],
      "source": [
        "# Load the Lena image and plot it\n",
        "url = \"../data/images/lena.gif\"\n",
        "original = cv2.imread(url, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "# Noisy image\n",
        "noisy = addingNoise(original, 0, 10)\n",
        "\n",
        "# Show the images\n",
        "plt.figure(figsize=(15, 7))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(original, cmap=plt.cm.gray)\n",
        "plt.title(\"Lena - Original image\", pad=10)\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(noisy, cmap=plt.cm.gray)\n",
        "plt.title(\"Lena - Noisy image\", pad=10)\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0z9d7We6pg5"
      },
      "source": [
        "We consider only soft thresholding and we fix a set of possible threshold values to try.\n",
        "\n",
        "We will use as quality metric the **MSE** (*Mean Square Error*) which returns the error we incur in denoising the image, using a specific method, respect to the original image. Lower values indicate better performances.\n",
        "<br>It is defined as in the equation below:\n",
        "\n",
        "$$ MSE = \\frac{1}{\\text{wd}\\cdot\\text{ht}} \\cdot\\sum_{x=1}^{\\text{ht}}\\sum_{y=1}^{\\text{wd}}\\big(Img_{N_{x,y}} - Img_{x,y}\\big)^2 $$\n",
        "\n",
        "where $ Img_{N_{x,y}} $ and $ Img_{x,y} $ denote respectively the noisy and the original image pixel value in the $ i^{th} $ row and $ j^{th} $ column, $ \\text{wd} $ and $ \\text{ht} $ represent the width and height of the image.\n",
        "\n",
        "<br>\n",
        "\n",
        "Firstly, we do the work only considering one level 2D Haar wavelet transform.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lfXrT3r_66lq"
      },
      "outputs": [],
      "source": [
        "# Function to compute the MSE\n",
        "def MSE(modify, original):\n",
        "\n",
        "  # Try to commute the data matrix in float64 values\n",
        "  try:\n",
        "    modify = modify.astype(np.float64)\n",
        "    original = original.astype(np.float64)\n",
        "\n",
        "  # If it can't, raise an error\n",
        "  except:\n",
        "    raise TypeError(\"Bad data passed to the method!\")\n",
        "\n",
        "  # Compute MSE and return it\n",
        "  return np.mean((modify-original)**2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Lcnt50E268qV",
        "outputId": "7107db08-97fe-4e9d-ecb2-19597eceb0aa"
      },
      "outputs": [],
      "source": [
        "# Define some threshold values and the thresholding method\n",
        "threshold_values = np.arange(10, 91, 20)\n",
        "thresh_method = \"soft\"\n",
        "\n",
        "plt.figure(figsize=(30, 20))\n",
        "\n",
        "plt.subplot(2, 3, 1)\n",
        "plt.imshow(noisy, cmap=plt.cm.gray)\n",
        "mse = np.round(MSE(noisy, original), 4)\n",
        "plt.title(\"Noisy image - Gaussian noise, sigma = 10 - MSE: {}\".format(mse), pad=10)\n",
        "\n",
        "iter = 2\n",
        "for threshold_value in threshold_values:\n",
        "\n",
        "  # Do a one level 2D Haar wavelet transform\n",
        "  LL, (LH, HL, HH) = pywt.dwt2(noisy, \"haar\")\n",
        "\n",
        "  # Apply the thresholding method to each of the high-frequency sub-bands given the threshold_value\n",
        "  LH_ = thresholding(LH, thresh_method, threshold_value)\n",
        "  HL_ = thresholding(HL, thresh_method, threshold_value)\n",
        "  HH_ = thresholding(HH, thresh_method, threshold_value)\n",
        "\n",
        "  # Reconstruct the image using the 2D Haar inverse wavelet transform\n",
        "  LL = pywt.idwt2((LL, (LH_, HL_, HH_)), \"haar\")\n",
        "\n",
        "  # Adapt the final (denoised) image to the range 0-255 with uint8 values\n",
        "  LL[LL < 0] = 0\n",
        "  LL[LL > 255] = 255\n",
        "  denoised_image = np.uint8(LL)\n",
        "\n",
        "  plt.subplot(2, 3, iter)\n",
        "  plt.imshow(denoised_image, cmap=plt.cm.gray)\n",
        "  mse = np.round(MSE(denoised_image, original), 4)\n",
        "  plt.title(\"Denoised image - Soft thresholding - threshold = {} - MSE: {}\".format(\n",
        "    threshold_value, mse), pad=10)\n",
        "\n",
        "  iter += 1\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lcrv20aW6-t0"
      },
      "source": [
        "By the results obtained, we can see that one pass of the Haar wavelet is not sufficient to do a good denoising work on the image. We can only see through our quality parameter (MSE) that the optimal threshold value can be researched around 10 or 30.\n",
        "\n",
        "So, we restrict the interval for the threshold value and we try to implement a three level Haar wavelet decomposition, applying at each level the same thresholding method and value.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "N6kvWAZI7BSy",
        "outputId": "7436fb9d-c955-4188-9169-6b616e7868ff"
      },
      "outputs": [],
      "source": [
        "# Define some threshold values and the thresholding method\n",
        "threshold_values = np.arange(5, 26, 5)\n",
        "thresh_method = \"soft\"\n",
        "\n",
        "plt.figure(figsize=(30, 20))\n",
        "\n",
        "plt.subplot(2,3,1)\n",
        "plt.imshow(noisy, cmap=plt.cm.gray)\n",
        "mse = np.round(MSE(noisy, original), 4)\n",
        "plt.title(\"Noisy image - Gaussian noise, sigma = 10 - MSE: {}\".format(mse), pad=10)\n",
        "\n",
        "iter = 2\n",
        "for threshold_value in threshold_values:\n",
        "\n",
        "  # Do a one level 2D Haar wavelet transform\n",
        "  LL, (LH, HL, HH) = pywt.dwt2(noisy, \"haar\")\n",
        "\n",
        "  # Do a second level 2D Haar wavelet transform\n",
        "  LL2, (LH2, HL2, HH2) = pywt.dwt2(LL, \"haar\")\n",
        "\n",
        "  # Do a third level 2D Haar wavelet transform\n",
        "  LL3, (LH3, HL3, HH3) = pywt.dwt2(LL2, \"haar\")\n",
        "\n",
        "  # Apply the thresholding method to each of the high-frequency sub-bands given the threshold value\n",
        "  LH3_ = thresholding(LH3, thresh_method, threshold_value)\n",
        "  HL3_ = thresholding(HL3, thresh_method, threshold_value)\n",
        "  HH3_ = thresholding(HH3, thresh_method, threshold_value)\n",
        "\n",
        "  # Reconstruct the LL sub-band using the 2D Haar inverse wavelet transform\n",
        "  LL2 = pywt.idwt2((LL3, (LH3_, HL3_, HH3_)), \"haar\")\n",
        "\n",
        "  # Apply the thresholding method to each of the high-frequency sub-bands given the threshold value\n",
        "  LH2_ = thresholding(LH2, thresh_method, threshold_value)\n",
        "  HL2_ = thresholding(HL2, thresh_method, threshold_value)\n",
        "  HH2_ = thresholding(HH2, thresh_method, threshold_value)\n",
        "\n",
        "  # Reconstruct the LL sub-band using the 2D Haar inverse wavelet transform\n",
        "  LL = pywt.idwt2((LL2, (LH2_, HL2_, HH2_)), \"haar\")\n",
        "\n",
        "  # Apply the thresholding method to each of the high-frequency sub-bands given the threshold value\n",
        "  LH_ = thresholding(LH, thresh_method, threshold_value)\n",
        "  HL_ = thresholding(HL, thresh_method, threshold_value)\n",
        "  HH_ = thresholding(HH, thresh_method, threshold_value)\n",
        "\n",
        "  # Reconstruct the image using the 2D Haar inverse wavelet transform\n",
        "  LL = pywt.idwt2((LL, (LH_, HL_, HH_)), \"haar\")\n",
        "\n",
        "  # Adapt the final (denoised) image to the range 0-255 with uint8 values\n",
        "  LL[LL < 0] = 0\n",
        "  LL[LL > 255] = 255\n",
        "  denoised_image = np.uint8(LL)\n",
        "\n",
        "  plt.subplot(2, 3, iter)\n",
        "  plt.imshow(denoised_image, cmap=plt.cm.gray)\n",
        "  mse = np.round(MSE(denoised_image, original), 4)\n",
        "  plt.title(\"Denoised image - Soft thresholding - threshold = {} - MSE: {}\".format(\n",
        "    threshold_value, mse), pad=10)\n",
        "\n",
        "  iter += 1\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5n2AnKO7DpD"
      },
      "source": [
        "By increasing the number of levels of decomposition, we observe that as the threshold value increases, the image becomes increasingly grainy.\n",
        "\n",
        "This happens because as we go down the level, we get an increasingly coarse approximation of the image and the relative detail coefficients are an integral part of the image itself rather than noise.\n",
        "\n",
        "We can think in this way: the more we drop in level, the more our threshold must decrease since we will consider as noise only those pixels that are gradually more and more similar (therefore with detail coefficients close to zero) to their neighboring pixels.\n",
        "\n",
        "After some tests, we decide to divide the threshold value at each level by the $ \\text{level} $ factor.\n",
        "\n",
        "So, we will implement the new denoising algorithm and we will comment the results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "67nYtJ3s7Gej",
        "outputId": "699b21cc-f3e8-4c78-adcc-4d92a933dca4"
      },
      "outputs": [],
      "source": [
        "# Define some threshold values and the thresholding method\n",
        "threshold_values = np.arange(7.5, 21.6, 3.5)\n",
        "thresh_method = \"soft\"\n",
        "\n",
        "plt.figure(figsize=(30, 20))\n",
        "\n",
        "plt.subplot(2,3,1)\n",
        "plt.imshow(noisy, cmap=plt.cm.gray)\n",
        "mse = np.round(MSE(noisy, original), 4)\n",
        "plt.title(\"Noisy image - Gaussian noise, sigma = 10 - MSE: {}\".format(mse), pad=10)\n",
        "\n",
        "iter = 2\n",
        "for threshold_value in threshold_values:\n",
        "\n",
        "  # Do a one level 2D Haar wavelet transform\n",
        "  LL, (LH, HL, HH) = pywt.dwt2(noisy, \"haar\")\n",
        "\n",
        "  # Do a second level 2D Haar wavelet transform\n",
        "  LL2, (LH2, HL2, HH2) = pywt.dwt2(LL, \"haar\")\n",
        "\n",
        "  # Do a third level 2D Haar wavelet transform\n",
        "  LL3, (LH3, HL3, HH3) = pywt.dwt2(LL2, \"haar\")\n",
        "\n",
        "  # Apply the thresholding method to each of the high-frequency sub-bands given the threshold value\n",
        "  LH3_ = thresholding(LH3, thresh_method, threshold_value/3)\n",
        "  HL3_ = thresholding(HL3, thresh_method, threshold_value/3)\n",
        "  HH3_ = thresholding(HH3, thresh_method, threshold_value/3)\n",
        "\n",
        "  # Reconstruct the LL sub-band using the 2D Haar inverse wavelet transform\n",
        "  LL2 = pywt.idwt2((LL3, (LH3_, HL3_, HH3_)), \"haar\")\n",
        "\n",
        "  # Apply the thresholding method to each of the high-frequency sub-bands given the threshold value\n",
        "  LH2_ = thresholding(LH2, thresh_method, threshold_value/2)\n",
        "  HL2_ = thresholding(HL2, thresh_method, threshold_value/2)\n",
        "  HH2_ = thresholding(HH2, thresh_method, threshold_value/2)\n",
        "\n",
        "  # Reconstruct the LL sub-band using the 2D Haar inverse wavelet transform\n",
        "  LL = pywt.idwt2((LL2, (LH2_, HL2_, HH2_)), \"haar\")\n",
        "\n",
        "  # Apply the thresholding method to each of the high-frequency sub-bands given the threshold value\n",
        "  LH_ = thresholding(LH, thresh_method, threshold_value)\n",
        "  HL_ = thresholding(HL, thresh_method, threshold_value)\n",
        "  HH_ = thresholding(HH, thresh_method, threshold_value)\n",
        "\n",
        "  # Reconstruct the image using the 2D Haar inverse wavelet transform\n",
        "  LL = pywt.idwt2((LL, (LH_, HL_, HH_)), \"haar\")\n",
        "\n",
        "  # Adapt the final (denoised) image to the range 0-255 with uint8 values\n",
        "  LL[LL < 0] = 0\n",
        "  LL[LL > 255] = 255\n",
        "  denoised_image = np.uint8(LL)\n",
        "\n",
        "  plt.subplot(2, 3, iter)\n",
        "  plt.imshow(denoised_image, cmap=plt.cm.gray)\n",
        "  mse = np.round(MSE(denoised_image, original), 4)\n",
        "  plt.title(\"Denoised image - Soft thresholding - threshold = {} - MSE: {}\".format(\n",
        "    threshold_value, mse), pad=10)\n",
        "\n",
        "  iter += 1\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ByVHTss7I6Q"
      },
      "source": [
        "After this last step, we can see how we have just implemented a simple method that permits through three levels wavelet decomposition to clean an image from the noise, selecting the optimal threshold parameter using a quantitative value for the error (MSE) and a qualitative point of view (how the denoised image appears to our eyes, in terms of granularity, blur and smoothness).\n",
        "\n",
        "In this case, we will choose $ 14.5 $ as value for the threshold parameter.\n",
        "\n",
        "<br>\n",
        "\n",
        "The last question is: does the threshold parameter change if the quantity of noise in the image increases?\n",
        "\n",
        "We will try it with the same image adding a larger amount of noise ($ \\sigma = 15 $) and the last version of our denoising procedure. We will test a larger interval for the threshold value and we will comment the results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PfIsJnJI7Lnr",
        "outputId": "b4d7f633-c54e-473e-9472-15e6c9583c2a"
      },
      "outputs": [],
      "source": [
        "# Noisy image\n",
        "noisy = addingNoise(original, 0, 15)\n",
        "# Define some threshold values and the thresholding method\n",
        "threshold_values = np.arange(20, 91, 15)\n",
        "thresh_method = \"soft\"\n",
        "\n",
        "plt.figure(figsize=(30, 20))\n",
        "\n",
        "plt.subplot(2,3,1)\n",
        "plt.imshow(noisy, cmap=plt.cm.gray)\n",
        "mse = np.round(MSE(noisy, original), 4)\n",
        "plt.title(\"Noisy image - Gaussian noise, sigma = 15 - MSE: {}\".format(mse), pad=10)\n",
        "\n",
        "iter = 2\n",
        "for threshold_value in threshold_values:\n",
        "\n",
        "  # Do a one level 2D Haar wavelet transform\n",
        "  LL, (LH, HL, HH) = pywt.dwt2(noisy, \"haar\")\n",
        "\n",
        "  # Do a second level 2D Haar wavelet transform\n",
        "  LL2, (LH2, HL2, HH2) = pywt.dwt2(LL, \"haar\")\n",
        "\n",
        "  # Do a third level 2D Haar wavelet transform\n",
        "  LL3, (LH3, HL3, HH3) = pywt.dwt2(LL2, \"haar\")\n",
        "\n",
        "  # Apply the thresholding method to each of the high-frequency sub-bands given the threshold value\n",
        "  LH3_ = thresholding(LH3, thresh_method, threshold_value/4)\n",
        "  HL3_ = thresholding(HL3, thresh_method, threshold_value/4)\n",
        "  HH3_ = thresholding(HH3, thresh_method, threshold_value/4)\n",
        "\n",
        "  # Reconstruct the LL sub-band using the 2D Haar inverse wavelet transform\n",
        "  LL2 = pywt.idwt2((LL3, (LH3_, HL3_, HH3_)), \"haar\")\n",
        "\n",
        "  # Apply the thresholding method to each of the high-frequency sub-bands given the threshold value\n",
        "  LH2_ = thresholding(LH2, thresh_method, threshold_value/3)\n",
        "  HL2_ = thresholding(HL2, thresh_method, threshold_value/3)\n",
        "  HH2_ = thresholding(HH2, thresh_method, threshold_value/3)\n",
        "\n",
        "  # Reconstruct the LL sub-band using the 2D Haar inverse wavelet transform\n",
        "  LL = pywt.idwt2((LL2, (LH2_, HL2_, HH2_)), \"haar\")\n",
        "\n",
        "  # Apply the thresholding method to each of the high-frequency sub-bands given the threshold value\n",
        "  LH_ = thresholding(LH, thresh_method, threshold_value/2)\n",
        "  HL_ = thresholding(HL, thresh_method, threshold_value/2)\n",
        "  HH_ = thresholding(HH, thresh_method, threshold_value/2)\n",
        "\n",
        "  # Reconstruct the image using the 2D Haar inverse wavelet transform\n",
        "  LL = pywt.idwt2((LL, (LH_, HL_, HH_)), \"haar\")\n",
        "\n",
        "  # Adapt the final (denoised) image to the range 0-255 with uint8 values\n",
        "  LL[LL < 0] = 0\n",
        "  LL[LL > 255] = 255\n",
        "  denoised_image = np.uint8(LL)\n",
        "\n",
        "  plt.subplot(2, 3, iter)\n",
        "  plt.imshow(denoised_image, cmap=plt.cm.gray)\n",
        "  mse = np.round(MSE(denoised_image, original), 4)\n",
        "  plt.title(\"Denoised image - Soft thresholding - threshold = {} - MSE: {}\".format(\n",
        "    threshold_value, mse), pad=10)\n",
        "\n",
        "  iter += 1\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMeeRzNI7OH6"
      },
      "source": [
        "What we obtain is exactly what we expected: with a higher amount of noise added to the image, the algorithm required a bigger value for the threshold parameter. Observing the results, an optimal value can be found near 50, which permits to achieve a good denoising performance on the image without affecting too much everything that is not noise, so the image signal.\n",
        "\n",
        "The need to increase the value of this parameter is due to the fact that, now, the noise represents a clearer component that generates discrepancies between neighboring pixels that are also quite significant. These differences result in higher values of the detail coefficients and, therefore, this requires a higher threshold value.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCsKZxx93pg3"
      },
      "source": [
        "Doing this job each time we want to clean an image from noise is crazy (or maybe not).\n",
        "\n",
        "As we said before, there exists some methods that permits, with or without data information, to define an \"optimal\" value for the threshold parameter.\n",
        "\n",
        "<br>\n",
        "\n",
        "<b>*VisuShrink*</b> is thresholding by applying the *Universal threshold* porposed by Donoho and Johnstone. This threshold is given by:\n",
        "\n",
        "$$ T = \\sqrt{2 \\cdot \\hat\\sigma^2 \\cdot ln(N)} $$\n",
        "\n",
        "where $ \\hat\\sigma^2 $ is the noise variance and $ N $ is the number of pixels in the image. \n",
        "<br>The noise variance is found by *Robust Median Estimator* and it can be seen as the median absolute deviation of the diagonal detail coefficients of the first level decomposition. It is given by:\n",
        "\n",
        "$$ \\hat\\sigma^2 = \\Bigg(\\frac{\\text{median}(|Y_{x,y}|)}{0.6745}\\Bigg)^2, \\quad Y_{x,y} \\in HH_1 $$\n",
        "\n",
        "<br>As we can understand, it is a *universal threshold* because it keeps the same value regardless of the level of decomposition at which it is.\n",
        "<br>As we can see after, this is not the best possible value for the threshold parameter, in particular with high level of noise in the image, because it tends to smooth and blur too much.\n",
        "\n",
        "<br>\n",
        "\n",
        "<b>*BayesShrink*</b> can be seen as a method to find an adaptive threshold value that depends on the specific sub-band it is considering, in particular by its standard deviation. This threshold is given by:\n",
        "\n",
        "$$ T = \\frac{\\hat\\sigma^2}{\\hat\\sigma_S} $$\n",
        "\n",
        "where:\n",
        "- $ T $ is the threshold value;\n",
        "- $ \\hat\\sigma^2 $ is the noise variance in the image (found with the *RME*, as before);\n",
        "- $ \\hat\\sigma_S $ is the standard deviation for the specific high-frequency sub-band $ S $, given by: \n",
        "\n",
        " $$ \\hat\\sigma_S = \\sqrt{\\text{max}(\\hat\\sigma_Y^2 - \\hat\\sigma^2, 0)} \\text{ ,} \\quad \\text{where} \\quad \\hat\\sigma_Y^2 = \\frac{1}{N} \\sum_{i,j = 1}^N Y_{i,j}^2 \\quad \\text{with} \\quad Y_{i,j} \\in S $$\n",
        "\n",
        "<br>So, the threshold is inversely proportional to the standard deviation of $ S $, and proportional to the noise variance of the image. When $ \\frac{\\hat\\sigma^2}{\\hat\\sigma_S} \\ll 1 $, the signal is much stronger than the noise: the threshold value is chosen to be small in order to preserve most of the signal and remove some of the noise; instead, when $ \\frac{\\hat\\sigma^2}{\\hat\\sigma_S} \\gg 1 $, the noise dominates and the threshold is chosen to be large to remove the noise which has exacted the signal. Thus, this threshold choice adapts to both the signal and the noise characteristics as reflected\n",
        "in the parameters $ \\hat\\sigma^2 $ and $ \\hat\\sigma_S $.\n",
        "\n",
        "<br>\n",
        "\n",
        "<b>*VisuShrinkMod*</b> is based on the *VisuShrink* threshold value, with the difference that now the value depends also on the decomposition level at which the algorithm is working. This can be defined as:\n",
        "\n",
        "$$ T = \\frac{\\sqrt{2 \\cdot \\hat\\sigma^2 \\cdot ln(N)}}{l+1} $$\n",
        "\n",
        "where $ l $ identifies the decomposition level.\n",
        "\n",
        "If we think about what we said in the introduction, the noise energy rapidly decreases when the algorithm goes in deeper decomposition levels, instead the signal energy (of the image) remains stable. So, what we want to do is to decrease the value of threshold at each decomposition level to permits to not delete signal information but only the noisy one. This threshold implementation permits to do this.\n",
        "\n",
        "<br>\n",
        "\n",
        "So, we have three different type of threshold values:\n",
        "- *VisuShrink*: depends only on the noise variance in the image and its size, it is always the same;\n",
        "\n",
        "- *BayesShrink*: is an adaptive threshold that depends on the standard deviation of the specific sub-band, so it depends on the data it is analyzing;\n",
        "\n",
        "- *VisuShrinkMod*: is very similar to the first one, but it depends on the decomposition level at which the algorithm is, regardless of the data available.\n",
        "\n",
        "<br>\n",
        "\n",
        "We just have to move on to the implementation phase of the methods to compute the threshold value and the denoising procedure, and to apply it on the test images.\n",
        "<br><br>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wF4w5Uw38M5w"
      },
      "source": [
        "## 3. Implementation part\n",
        "\n",
        "In this section, we will implement the *optimal_T_value()* function, which permits to return the optimal value for the threshold respect to the selected type of threshold we want.\n",
        "\n",
        "Then, we will implement the multiple levels 2D Haar wavelet transform denoising algorithm.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YRbenUi_Dhk"
      },
      "source": [
        "The *optimal_T_value()* function requires some parameters:\n",
        "- $ \\text{compute\\_T\\_method} $ : the method to use to define the value of threshold (*VisuShrink*, *BayesShrink* or *VisuShrinkMod*);\n",
        "- $ \\text{sigma\\_hat} $ : the noise standard deviation calculated with the *RME* on the first level high-high sub-band ($ HH_1 $);\n",
        "- $ \\text{S} $ : the data matrix containing pixel values of a sub-band;\n",
        "- $ \\text{level} $ : decomposition level."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tVwyMem5ut88"
      },
      "outputs": [],
      "source": [
        "# Function that returns the optimal threshold value respect to the choosen method\n",
        "def optimal_T_value(compute_T_method, sigma_hat, S=[], level=0):\n",
        "\n",
        "  # Check the noise standard deviation value: if it does not respect the rule, raise an error\n",
        "  if sigma_hat < 0:\n",
        "    raise ValueError(\"\"\"The noise standard deviation value must be greater or equal \n",
        "                        than zero!\"\"\")\n",
        "\n",
        "  # VisuShrink implementation, requires only the noise standard deviation parameter\n",
        "  if compute_T_method == \"VisuShrink\":\n",
        "      return sigma_hat * np.sqrt(2 * np.log(512**2))\n",
        "\n",
        "  # BayesShrink implementation, requires the noise standard deviation and the image_data parameters\n",
        "  elif compute_T_method == \"BayesShrink\":\n",
        "      sigma_S = np.sqrt(np.max([np.mean(S**2) - sigma_hat**2, 1e-3]))\n",
        "      return sigma_hat**2 / sigma_S\n",
        "\n",
        "  # VisuShrinkMod implemetation, requires the noise standard deviation and the level parameters\n",
        "  elif compute_T_method == \"VisuShrinkMod\":\n",
        "    # Check the decomposition level value\n",
        "    if level > 0:\n",
        "      return optimal_T_value(\"VisuShrink\", sigma_hat) / (level+1)\n",
        "    # Raise an error if the level value is not correct\n",
        "    else:\n",
        "      raise ValueError(\"Level value needs to be greater than zero!\")\n",
        "\n",
        "  # If compute_T_method is not equal to one of the before, it is incorrect: raise an error\n",
        "  else:\n",
        "    raise ValueError(\"The selected method does not exist!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IE-hp0CA_YHz"
      },
      "source": [
        "Finally, we can implement the denoising procedure based on multiple level decomposition of the wavelets. We build a method that takes different parameters to guarantee some choices on its running:\n",
        "- $ \\text{image} $ : the data matrix containing pixel values of the image we want to clean from noise;\n",
        "- $ \\text{thresh\\_method} $ : the method to use to do thresholding on the high-frequency sub-bands (*hard* or *soft*);\n",
        "- $ \\text{compute\\_T\\_method} $ : the method to use to define the value of threshold (*VisuShrink*, *BayesShrink* or *VisuShrinkMod*);\n",
        "- $ \\text{max\\_level} $ : the maximum level of decomposition of the wavelets we want (-1 for the maximum possible level);\n",
        "- $ \\text{level} $ : **This parameter is only used by the method, the user has not to set it**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-FP6VqVs_eBf"
      },
      "outputs": [],
      "source": [
        "# Global variables\n",
        "sigma_hat = -1\n",
        "recursive = True\n",
        "\n",
        "# Function that returns a denoised version of the given input image (noisy one)\n",
        "def denoiseWavelet(image, thresh_method, compute_T_method, max_level=-1, level=1):\n",
        "\n",
        "  # Recall global variables\n",
        "  global sigma_hat, recursive\n",
        "  \n",
        "  # If this is the first level decomposition\n",
        "  if level == 1:\n",
        "    \n",
        "    # If max_level is equal to -1, set it to the maximum possible number of decomposition levels of the wavelet\n",
        "    if (max_level == -1):\n",
        "      max_level = np.floor(np.log2(image.shape[0]))\n",
        "    \n",
        "    # If the passed value for max_level is incorrect, raise an error\n",
        "    elif (max_level < -1) | (max_level == 0) | \\\n",
        "      (max_level > np.floor(np.log2(image.shape[0]))):\n",
        "      raise ValueError(\"\"\"Please, insert a correct max_level! \n",
        "                          Insert -1 if you want the maximum possible!\"\"\")\n",
        "\n",
        "    # Set recursive to True to enter the while loop\n",
        "    # It is necessary to recursively call this function until the max_level level of decomposition is reached\n",
        "    recursive = True\n",
        "\n",
        "  # Until max_level decomposition level is reached or recursive is True\n",
        "  while (level <= max_level) & recursive:\n",
        "    \n",
        "    # Do a one level 2D Haar wavelet transform\n",
        "    LL, (LH, HL, HH) = pywt.dwt2(image, \"haar\")\n",
        "\n",
        "    # If this is the first level, update the value of sigma_hat (noise standard deviation of the first level high-high sub-band)\n",
        "    if level == 1:\n",
        "      sigma_hat = np.median(np.abs(HH))/0.6745\n",
        "\n",
        "    # Increment the level value to the next one\n",
        "    level += 1\n",
        "    \n",
        "    # Recursively call the denoiseWavelet method on the low-low sub-band to compute another level of decomposition\n",
        "    LL, level = denoiseWavelet(LL, thresh_method, compute_T_method, max_level, level)\n",
        "      \n",
        "  # When exit the while loop, it means that it reaches the max_level level of decomposition\n",
        "  # So, set recursive to False and start to go backward, thresholding the high-frequency sub-bands and \n",
        "  # rebuilding the image through each level of decomposition\n",
        "  if recursive:\n",
        "    recursive = False\n",
        "    return image, level\n",
        "  \n",
        "  # Recursive is False: do the thresholding and rebuild the image of the current level\n",
        "  else:\n",
        "    \n",
        "    # Decrease the level value of one\n",
        "    level -= 1\n",
        "\n",
        "    # Compute the threshold value for each of the high-frequency sub-bands\n",
        "    T_LH = optimal_T_value(compute_T_method, sigma_hat, LH, level)\n",
        "    T_HL = optimal_T_value(compute_T_method, sigma_hat, HL, level)\n",
        "    T_HH = optimal_T_value(compute_T_method, sigma_hat, HH, level)\n",
        "\n",
        "    # Apply the thresholding method to each of the high-frequency sub-bands given the threshold values just computed\n",
        "    LH_ = thresholding(LH, thresh_method, T_LH)\n",
        "    HL_ = thresholding(HL, thresh_method, T_HL)\n",
        "    HH_ = thresholding(HH, thresh_method, T_HH)\n",
        "\n",
        "    # Reconstruct the current level LL (low-low sub-band) using the 2D Haar inverse wavelet transform\n",
        "    LL = pywt.idwt2((LL, (LH_, HL_, HH_)), \"haar\")\n",
        "\n",
        "    # If this is the latest level of reconstruction of the image\n",
        "    if level == 1:\n",
        "      \n",
        "      # Adapt the final (denoised) image to the range 0-255 with uint8 value\n",
        "      LL[LL < 0] = 0\n",
        "      LL[LL > 255] = 255\n",
        "      LL = np.uint8(LL)\n",
        "      \n",
        "      # Return the denoised image\n",
        "      return LL\n",
        "\n",
        "    # If this is not the latest level, return the LL sub-band and the current level to close one recursive call of denoiseWavelet\n",
        "    return LL, level\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioOA1YqriT_8"
      },
      "source": [
        "<br>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lYD0ZM3_g-Q"
      },
      "source": [
        "## 4. Experiments and results\n",
        "\n",
        "The denoising threshold algorithms compared are *VisuShrink*, *BayesShrink* and *VisuShrinkMod*. \n",
        "\n",
        "In our implementation, *hard thresholding* and *soft thresholding* are used to evaluate these threshold selection algorithms. \n",
        "\n",
        "The wavelet used in our experiment is the 2D Haar discrete wavelet transform. \n",
        "\n",
        "We test the denoising procedure we implemented: it analyzes multiple level decomposition of the wavelets to better clean the image from the noise.\n",
        "\n",
        "The experiments are conducted on a gray scale test image, *Lena*, of size 512  512 pixels at different noise levels: $\\sigma \\in \\{5, \\text{ } 7.5, \\text{ } 10, \\text{ } 12.5, \\text{ } 15\\} $.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHNkrr2TAPXZ"
      },
      "source": [
        "### 4.1. Objective evaluation method\n",
        "\n",
        "The performance of the proposed image denoising strategy in this work is evaluated in terms of PSNR (*Peak Signal-to-Noise Ratio*), for 8bit gray scale images. This is an engineering term for the ratio between the maximum possible power of a signal and the power of corrupting noise that affects the fidelity of its representation.\n",
        "\n",
        "<br>In order to evaluate the PSNR value, we have to compute the MSE of an image. We can do this using the already implemented version of the MSE.\n",
        "\n",
        "<br>Then, the objective quality of the reconstructed image is measured by the PSNR, computed as follows:\n",
        "\n",
        "$$ PSNR = 10 \\cdot log_{10}\\Bigg(\\frac{255^2}{MSE}\\Bigg) dB $$\n",
        "\n",
        "<br>\n",
        "\n",
        "Then, now, we will implement this evaluation method.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "83y9qqL-ALGg"
      },
      "outputs": [],
      "source": [
        "# Function that is used to evaluate the quality of denoised images with respect to the original one\n",
        "def PSNR(modify, original):\n",
        "\n",
        "  # Try to commute the data matrix in float64 values\n",
        "  try:\n",
        "    modify = modify.astype(np.float64)\n",
        "    original = original.astype(np.float64)\n",
        "  # If it can't, raise an error\n",
        "  except:\n",
        "    raise TypeError(\"Bad data passed to the method!\")\n",
        "\n",
        "  # Compute the MSE\n",
        "  MSE_value = MSE(modify, original)\n",
        "  # Compute the PSNR\n",
        "  PSNR = 10*np.log10(255**2/MSE_value)\n",
        "  \n",
        "  # Return the PSNR\n",
        "  return PSNR\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rYWmAlYAij8"
      },
      "source": [
        "### 4.2. Lena image test\n",
        "\n",
        "We start reloading the *Lena* image.\n",
        "\n",
        "Then, we will iterate over different list to test all the possible combinations between different $ \\sigma $ values for noise, thresholding methods and algorithms to compute the optimal threshold value, using five decomposition levels of wavelets.\n",
        "\n",
        "Once the results are obtained, we will rearrange them in a table to make them as explicit as possible and we will show some examples of bad/good denoised images.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nbpIE2tEAmWY"
      },
      "outputs": [],
      "source": [
        "# Load the Lena image\n",
        "url = \"../data/images/lena.gif\"\n",
        "original = cv2.imread(url, cv2.IMREAD_GRAYSCALE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7vkF-1MAvLm"
      },
      "outputs": [],
      "source": [
        "# Prepare the test list for each of the parameters\n",
        "sigmas = np.arange(5, 15.1, 2.5)\n",
        "T_methods = [\"VisuShrink\", \"BayesShrink\", \"VisuShrinkMod\"]\n",
        "thresh_methods = [\"hard\", \"soft\"]\n",
        "\n",
        "# Initialize the list which will contain the denoised images and the respective PSNR values\n",
        "PSNRs_noisy = []\n",
        "denoised_images = []\n",
        "PSNRs_denoised = []\n",
        "\n",
        "# Do all the test and fill the denoised_images and PSNRs lists\n",
        "# For each sigma (noise)\n",
        "for sigma in sigmas:\n",
        "  # Create a noisy version of the image adding Gaussian noise with mean equals zero and standard deviation equal to sigma\n",
        "  noisy = addingNoise(original, 0, sigma)\n",
        "  PSNRs_noisy.append(PSNR(noisy, original))\n",
        "  # For each of the methods to define the threshold value\n",
        "  for T_method in T_methods:\n",
        "    # For each of the thresholding methods\n",
        "    for thresh_method in thresh_methods:\n",
        "      # Apply the denoising method to the image and save the result in the denoised_images list\n",
        "      denoised_images.append(denoiseWavelet(image=noisy, thresh_method=thresh_method, compute_T_method=T_method, max_level=5))\n",
        "      # Compute the PSNR of the current denoised image with respect to the original one\n",
        "      PSNRs_denoised.append(PSNR(denoised_images[-1], original))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 736
        },
        "id": "KbeyR5k2AzUC",
        "outputId": "7072b0b7-d2ba-4576-96ef-28da2d7c021c"
      },
      "outputs": [],
      "source": [
        "# Prepare multi index for rows\n",
        "iterables = [sigmas, T_methods]\n",
        "multi_idx = pd.MultiIndex.from_product(iterables, names=[\"sigma\", \"T_method\"])\n",
        "# Prepare index for columns\n",
        "variables = pd.Index(thresh_methods, name=\"thresh_method\")\n",
        "\n",
        "# Reshape the data and build the dataframe\n",
        "PSNRs_denoised = np.reshape(np.array(PSNRs_denoised), (15, 2))\n",
        "PSNRs_denoised = pd.DataFrame(PSNRs_denoised, index=multi_idx, columns=variables)\n",
        "\n",
        "# Rearrange the PSNR values for the noisy images\n",
        "PSNRs_noisy = np.reshape(np.array(PSNRs_noisy), (1, 5))\n",
        "PSNRs_noisy = pd.DataFrame(np.reshape(np.array(PSNRs_noisy), (1, 5)), \n",
        "                           columns=pd.Index(sigmas, name=\"sigma\"))\n",
        "\n",
        "# Show tables\n",
        "print(\"PSNRs noisy images:\")\n",
        "display(PSNRs_noisy)\n",
        "print(\"\\n\\n-----------------------------------------------------------------\\n\\n\")\n",
        "print(\"PSNRs denoised images:\")\n",
        "display(PSNRs_denoised)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pmrpU5NA71m"
      },
      "source": [
        "As we can see from the tables above, in general, the PSNR value decreases when the amount of noise added to the image ($ \\sigma $ value) increases: so, bigger is the noise, worst the denoising of the image is.\n",
        "\n",
        "The first thing that immediately catches the eye is that the *VisuShrink* method to find a value for the threshold always performs worst respect to the other two. This can be justified by the fact that it is a fixed value for each level of decomposition and this does not fit with what has been said previously: at each deeper level, the noise energy decreases and, therefore, the threshold level must decrease with it.\n",
        "What we expect are more and more distorted images as the noise increases.\n",
        "\n",
        "We take as examples the *VisuShrink* with the two thresholding methods with three different levels of noise to highlight this behavior.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ni6YQOUGBCJB",
        "outputId": "2f7763c7-62c7-47de-f403-239db66a777f"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(30, 20))\n",
        "\n",
        "plt.subplot(2, 3, 1)\n",
        "plt.imshow(denoised_images[0], cmap=plt.cm.gray)\n",
        "plt.title(\"VisuShrink - Hard thresholding - sigma: 5 - PSNR: {}\".format(\n",
        "    np.round(PSNR(denoised_images[0], original), 4)))\n",
        "\n",
        "plt.subplot(2, 3, 2)\n",
        "plt.imshow(denoised_images[12], cmap=plt.cm.gray)\n",
        "plt.title(\"VisuShrink - Hard thresholding - sigma: 10 - PSNR: {}\".format(\n",
        "    np.round(PSNR(denoised_images[12], original), 4)))\n",
        "\n",
        "plt.subplot(2, 3, 3)\n",
        "plt.imshow(denoised_images[24], cmap=plt.cm.gray)\n",
        "plt.title(\"VisuShrink - Hard thresholding - sigma: 15 - PSNR: {}\".format(\n",
        "    np.round(PSNR(denoised_images[24], original), 4)))\n",
        "\n",
        "plt.subplot(2, 3, 4)\n",
        "plt.imshow(denoised_images[1], cmap=plt.cm.gray)\n",
        "plt.title(\"VisuShrink - Soft thresholding - sigma: 5 - PSNR: {}\".format(\n",
        "    np.round(PSNR(denoised_images[1], original), 4)))\n",
        "\n",
        "plt.subplot(2, 3, 5)\n",
        "plt.imshow(denoised_images[13], cmap=plt.cm.gray)\n",
        "plt.title(\"VisuShrink - Soft thresholding - sigma: 10 - PSNR: {}\".format(\n",
        "    np.round(PSNR(denoised_images[13], original), 4)))\n",
        "\n",
        "plt.subplot(2, 3, 6)\n",
        "plt.imshow(denoised_images[25], cmap=plt.cm.gray)\n",
        "plt.title(\"VisuShrink - Soft thresholding - sigma: 15 - PSNR: {}\".format(\n",
        "    np.round(PSNR(denoised_images[25], original), 4)))\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpSMyEKfBU_y"
      },
      "source": [
        "The results reported confirms what we have just said: particularly, this behavior is amplified with the soft thresholding because this method, as we studied, returns images with smoother and blurrier edges respect than the other thresholding method.\n",
        "\n",
        "<br>\n",
        "\n",
        "Going forward with the analysis, we can also see, from the table, that the hard thresholding method performs worse than the soft one several times. So, this technique seems to not be the best possible one to use, since it performs a very strong thresholding on the pixels values. Doing this, if we think about high value of noise, it is not able to differentiate real values and the ones that are affected by noise, then it maintains a certain amount of noise which leads to poor denoising performances.\n",
        "<br>This respect exactly what we have learned in *The threshold value* section of this project.\n",
        "\n",
        "To be more explicit on the results, we show what happens with hard thresholding methods using *BayesShrink* and *VisuShrinkMod* with $ \\sigma \\in \\{5, 10, 15\\} $.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XfuLFh30Bl_V",
        "outputId": "d54136da-1864-489f-c125-6a4a783cb39c"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(30, 20))\n",
        "\n",
        "plt.subplot(2, 3, 1)\n",
        "plt.imshow(denoised_images[2], cmap=plt.cm.gray)\n",
        "plt.title(\"BayesShrink - Hard thresholding - sigma: 5 - PSNR: {}\".format(\n",
        "    np.round(PSNR(denoised_images[2], original), 4)))\n",
        "\n",
        "plt.subplot(2, 3, 2)\n",
        "plt.imshow(denoised_images[14], cmap=plt.cm.gray)\n",
        "plt.title(\"BayesShrink - Hard thresholding - sigma: 10 - PSNR: {}\".format(\n",
        "    np.round(PSNR(denoised_images[14], original), 4)))\n",
        "\n",
        "plt.subplot(2, 3, 3)\n",
        "plt.imshow(denoised_images[26], cmap=plt.cm.gray)\n",
        "plt.title(\"BayesShrink - Hard thresholding - sigma: 15 - PSNR: {}\".format(\n",
        "    np.round(PSNR(denoised_images[26], original), 4)))\n",
        "\n",
        "plt.subplot(2, 3, 4)\n",
        "plt.imshow(denoised_images[4], cmap=plt.cm.gray)\n",
        "plt.title(\"VisuShrinkMod - Hard thresholding - sigma: 5 - PSNR: {}\".format(\n",
        "    np.round(PSNR(denoised_images[4], original), 4)))\n",
        "\n",
        "plt.subplot(2, 3, 5)\n",
        "plt.imshow(denoised_images[16], cmap=plt.cm.gray)\n",
        "plt.title(\"VisuShrinkMod - Hard thresholding - sigma: 10 - PSNR: {}\".format(\n",
        "    np.round(PSNR(denoised_images[16], original), 4)))\n",
        "\n",
        "plt.subplot(2, 3, 6)\n",
        "plt.imshow(denoised_images[28], cmap=plt.cm.gray)\n",
        "plt.title(\"VisuShrinkMod - Hard thresholding - sigma: 15 - PSNR: {}\".format(\n",
        "    np.round(PSNR(denoised_images[28], original), 4)))\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnyQQ_A3B3Du"
      },
      "source": [
        "By comparing all the possible results obtained with hard thresholding and the methods to compute threshold, we can say that the best performances can be reached using the *VisuShrinkMod* method to compute the threshold parameter. It returns a denoised image which still contains a slight amount of noise (lower respect the other two) but it permits to preserve the edges of the objects in the image.\n",
        "\n",
        "We report the final example for hard thresholding, to emphasize the best performance of the *VisuShrinkMod* method with this type of thresholding.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 560
        },
        "id": "c_btUBa-nfWn",
        "outputId": "361bcb69-7d21-4615-c680-4269cbaa32ef"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(30, 10))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.imshow(original, cmap=plt.cm.gray)\n",
        "plt.title(\"Original image\", pad=10)\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "noisy_t = addingNoise(original, 0, 10)\n",
        "plt.imshow(noisy_t, cmap=plt.cm.gray)\n",
        "plt.title(\"Noisy image - sigma: 10 - PSNR: {}\".format(\n",
        "    np.round(PSNR(noisy_t, original), 4)))\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.imshow(denoised_images[16], cmap=plt.cm.gray)\n",
        "plt.title(\"VisuShrinkMod - Hard thresholding - sigma: 10 - PSNR: {}\".format(\n",
        "    np.round(PSNR(denoised_images[16], original), 4)))\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChnyKgWbnRi9"
      },
      "source": [
        "Now, we look now at the *soft thresholding* method and its behavior depending on the method chosen to calculate the threshold, *VisuShrink* excluded.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "a7RVOBftn-Je",
        "outputId": "a86871f2-3edc-465e-8f29-ef719c668512"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(30, 20))\n",
        "\n",
        "plt.subplot(2, 3, 1)\n",
        "plt.imshow(denoised_images[3], cmap=plt.cm.gray)\n",
        "plt.title(\"BayesShrink - Soft thresholding - sigma: 5 - PSNR: {}\".format(\n",
        "    np.round(PSNR(denoised_images[3], original), 4)))\n",
        "\n",
        "plt.subplot(2, 3, 2)\n",
        "plt.imshow(denoised_images[15], cmap=plt.cm.gray)\n",
        "plt.title(\"BayesShrink - Soft thresholding - sigma: 10 - PSNR: {}\".format(\n",
        "    np.round(PSNR(denoised_images[15], original), 4)))\n",
        "\n",
        "plt.subplot(2, 3, 3)\n",
        "plt.imshow(denoised_images[27], cmap=plt.cm.gray)\n",
        "plt.title(\"BayesShrink - Soft thresholding - sigma: 15 - PSNR: {}\".format(\n",
        "    np.round(PSNR(denoised_images[27], original), 4)))\n",
        "\n",
        "plt.subplot(2, 3, 4)\n",
        "plt.imshow(denoised_images[5], cmap=plt.cm.gray)\n",
        "plt.title(\"VisuShrinkMod - Soft thresholding - sigma: 5 - PSNR: {}\".format(\n",
        "    np.round(PSNR(denoised_images[5], original), 4)))\n",
        "\n",
        "plt.subplot(2, 3, 5)\n",
        "plt.imshow(denoised_images[17], cmap=plt.cm.gray)\n",
        "plt.title(\"VisuShrinkMod - Soft thresholding - sigma: 10 - PSNR: {}\".format(\n",
        "    np.round(PSNR(denoised_images[17], original), 4)))\n",
        "\n",
        "plt.subplot(2, 3, 6)\n",
        "plt.imshow(denoised_images[29], cmap=plt.cm.gray)\n",
        "plt.title(\"VisuShrinkMod - Soft thresholding - sigma: 15 - PSNR: {}\".format(\n",
        "    np.round(PSNR(denoised_images[29], original), 4)))\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2y8EbF7UmveD"
      },
      "source": [
        "Looking at the soft thresholding results, we can say that the denoised images obtained through the *VisuShrinkMod* appear a little blurrier than the ones obtained using the *BayesShrink* method, also they are a little bit grainy.\n",
        "<br>Using also the PSNR evaluation metric, we can confirm that the best results using soft thresholding method can be reached applying the *BayesShrink* method to define the threshold value during the denoising procedure.\n",
        "\n",
        "Therefore, as before, we report a final example for soft thresholding, to emphasize the best performance of the BayesShrink method with this type of thresholding.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        },
        "id": "cc6Vl78VCB4N",
        "outputId": "fd3c02cd-7ecd-4b30-87b7-c0bf0f3fddb9"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(30, 10))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.imshow(original, cmap=plt.cm.gray)\n",
        "plt.title(\"Original image\")\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "noisy_t = addingNoise(original, 0, 10)\n",
        "plt.imshow(noisy_t, cmap=plt.cm.gray)\n",
        "plt.title(\"Noisy image - sigma: 10 - PSNR: {}\".format(\n",
        "    np.round(PSNR(noisy_t, original), 4)))\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.imshow(denoised_images[15], cmap=plt.cm.gray)\n",
        "plt.title(\"BayesShrink - Soft thresholding - sigma: 10 - PSNR: {}\".format(\n",
        "    np.round(PSNR(denoised_images[15], original), 4)))\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6xQo6pguTUz"
      },
      "source": [
        "Fixed $ \\sigma = 10 $ for the amount of noise in the image, we will report the best denoised images obtained by the two thresholding method. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lCfvD1xetP-c",
        "outputId": "7718acb5-03e2-4450-f404-a3780e46de65"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15, 15))\n",
        "\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.imshow(original, cmap=plt.cm.gray)\n",
        "plt.title(\"Original image\")\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "noisy_t = addingNoise(original, 0, 10)\n",
        "plt.imshow(noisy_t, cmap=plt.cm.gray)\n",
        "plt.title(\"Noisy image - sigma: 10 - PSNR: {}\".format(\n",
        "    np.round(PSNR(noisy_t, original), 4)))\n",
        "\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.imshow(denoised_images[16], cmap=plt.cm.gray)\n",
        "plt.title(\"VisuShrinkMod - Hard thresholding - sigma: 10 - PSNR: {}\".format(\n",
        "    np.round(PSNR(denoised_images[16], original), 4)))\n",
        "\n",
        "plt.subplot(2, 2, 4)\n",
        "plt.imshow(denoised_images[15], cmap=plt.cm.gray)\n",
        "plt.title(\"BayesShrink - Soft thresholding - sigma: 10 - PSNR: {}\".format(\n",
        "    np.round(PSNR(denoised_images[15], original), 4)))\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rd2fNwrsCNgL"
      },
      "source": [
        "What we can say is that the best possible combination of parameters is soft thresholding with *BayesShrink* which returns a denoised image that is less blurred and with the intensity of the color closer to that of the original image than the one obtained using hard thresholding with *VisuShrinkMod*. A confirmation of this observation is once again given by the higher value recorded for the PSNR, the fidelity parameter.\n",
        "<br><br>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDYgJU_fDy_5"
      },
      "source": [
        "## 5. Conclusions and considerations\n",
        "\n",
        "Haar wavelets can be a very useful and powerful tool to clear the images from the noise, particularly Gaussian noise, which represents a very good candidate to replace other denoising methods.\n",
        "\n",
        "We have reported how the hard and soft thresholding work and how much difficult the choice of the threshold parameter can be.\n",
        "\n",
        "So, we introduce some \"standard method\" to define a value for this parameter which we have found in different works of other people.\n",
        "\n",
        "By the results we obtained, we have seen that the best possible configuration of the denoising procedure with Haar wavelets is using the soft thresholding method to operate over the details coefficients and to consider the *BayesShrink* method to define the value of the threshold.\n",
        "\n",
        "The denoising images have a good denoising quality which tends to decrease as the noise increases, in particular the standard deviation of the Gaussian noise: in fact, with higher level of noise, the resulting images can appear more grainy and blurry.\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "Finally, I can say that is a very good and simpler solution that can be useful in many cases and I had fun to implement it and to discover some \"tricks\" that helped me in solving the tasks.\n",
        "\n",
        "It was a job that took a long time but that led me to fully understand the concepts, its usefulness and that thrilled me.\n",
        "\n",
        "<br>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrZS96hYD4p6"
      },
      "source": [
        "## 6. References\n",
        "\n",
        "A list of all the articles, works and projects used to understand DBSCAN and build this laboratory:\n",
        "\n",
        "1.   Yang Qiang, \"Image denoising based on Haar wavelet transform\".\n",
        "     <br>*Proceedings of 2011 International Conference on Electronics and Optoelectronics, 2011, pp. V3-129-V3-132, doi: 10.1109/ICEOE.2011.6013318.*\n",
        "\n",
        "2.   J. Pang, \"Improved image denoising based on Haar wavelet transform\".\n",
        "     <br>*2017 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computed, Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI), 2017, pp. 1-6, doi: 10.1109/UIC-ATC.2017.8397456.*\n",
        "\n",
        "3.   S. H. Ismael, F. M. Mustafa and I. T. Okms, \"A New Approach of Image Denoising Based on Discrete Wavelet Transform\".\n",
        "     <br>*2016 World Symposium on Computer Applications & Research (WSCAR), 2016, pp. 36-40, doi: 10.1109/WSCAR.2016.30.*\n",
        "\n",
        "4.   Shivani Mupparaju, B Naga Venkata Satya Durga Jahnavi, \"Comparison of Various Thresholding Techniques of Image Denoising\".\n",
        "     <br>*Department of ECE, VNR VJIET, Hyderabad, A.P, India - International Journal of Engineering Research & Technology (IJERT), Vol. 2 Issue 9, September - 2013, ISSN: 2278-0181*.\n",
        "\n",
        "5.   Gregory R. Lee, Ralf Gommers, Filip Wasilewski, Kai Wohlfahrt, Aaron OLeary (2019). \"PyWavelets: A Python package for wavelet analysis\". \n",
        "     <br>*Journal of Open Source Software, 4(36), 1237, https://doi.org/10.21105/joss.01237.*\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "MEDONE_MARIO_-_Image_Denoising_using_Haar_Wavelets_FINAL.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "uni-env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
